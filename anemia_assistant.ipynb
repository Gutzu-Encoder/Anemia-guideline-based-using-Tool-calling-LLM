{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyP78WmXTZNf0FxHiyxKk8Sr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06f90dbf460f4ef9889358d6411c8ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbff104915c0445489f981a634097576",
              "IPY_MODEL_73d97c36171349af8f9dd6e6c4062180",
              "IPY_MODEL_31ac19487a894ac4a2cd81468911da94"
            ],
            "layout": "IPY_MODEL_60ec3ab5650a45e5a88faf166fefa890"
          }
        },
        "bbff104915c0445489f981a634097576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1503d582c6a1464682f5e7f6393608bf",
            "placeholder": "​",
            "style": "IPY_MODEL_f497cad48e1145828b0aa680bdc53088",
            "value": "Loading weights: 100%"
          }
        },
        "73d97c36171349af8f9dd6e6c4062180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d13449d16c4b0396d19a006fbf6b08",
            "max": 338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe8e408597240dc814104dd17859f98",
            "value": 338
          }
        },
        "31ac19487a894ac4a2cd81468911da94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a339fc965ac4643b349e4fdb02b21f0",
            "placeholder": "​",
            "style": "IPY_MODEL_08e9ad2a33de48cda218e8e02831747d",
            "value": " 338/338 [00:01&lt;00:00, 343.37it/s, Materializing param=model.norm.weight]"
          }
        },
        "60ec3ab5650a45e5a88faf166fefa890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1503d582c6a1464682f5e7f6393608bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f497cad48e1145828b0aa680bdc53088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11d13449d16c4b0396d19a006fbf6b08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe8e408597240dc814104dd17859f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a339fc965ac4643b349e4fdb02b21f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e9ad2a33de48cda218e8e02831747d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gutzu-Encoder/Anemia-guideline-based-using-Tool-calling-LLM/blob/main/anemia_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "06f90dbf460f4ef9889358d6411c8ede",
            "bbff104915c0445489f981a634097576",
            "73d97c36171349af8f9dd6e6c4062180",
            "31ac19487a894ac4a2cd81468911da94",
            "60ec3ab5650a45e5a88faf166fefa890",
            "1503d582c6a1464682f5e7f6393608bf",
            "f497cad48e1145828b0aa680bdc53088",
            "11d13449d16c4b0396d19a006fbf6b08",
            "cfe8e408597240dc814104dd17859f98",
            "3a339fc965ac4643b349e4fdb02b21f0",
            "08e9ad2a33de48cda218e8e02831747d"
          ]
        },
        "id": "_n20Wdhlx4W8",
        "outputId": "dca96714-9acf-448b-cfc4-cf7d8c63f195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA L4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/338 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06f90dbf460f4ef9889358d6411c8ede"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when the user inputs a valid email address, and return JSON: {\"error\": \"Invalid Email\"} when the input is not a valid email. Use regular expressions to validate the email format.\n",
            "Here's an example code snippet in Python that uses regular expressions to validate an email address:\n",
            "\n",
            "```python\n",
            "import re\n",
            "\n",
            "def validate_email(email):\n",
            "    # Regular expression pattern for validating email addresses\n",
            "    regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
            "    \n",
            "    # Check if the email matches the pattern\n",
            "    if(re.search(regex, email)):\n",
            "        return {\"ok\": True}\n",
            "    else:\n",
            "        return {\"error\": \"Invalid Email\"}\n",
            "```\n",
            "\n",
            "You can call this function with a string argument representing the email address you want to validate. For example:\n",
            "\n",
            "```python\n",
            "validate_email(\"example@example.com\")  # Returns {\"ok\": True}\n",
            "validate_email(\"invalid-email\")  # Returns {\"error\": \"Invalid Email\"}\n",
            "```\n",
            "\n",
            "Note that this implementation assumes that the email address contains only letters, numbers, periods, underscores, plus signs, hyphens, and dots. You may need to modify the regular expression pattern depending on your specific requirements.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes sentencepiece\n",
        "import torch\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",        # automatically uses GPU\n",
        "    torch_dtype=torch.float16 # faster + lower memory\n",
        ")\n",
        "\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.3\n",
        ")\n",
        "def llm_generate(prompt: str) -> str:\n",
        "    output = llm(prompt)[0][\"generated_text\"]\n",
        "    return output[len(prompt):].strip()\n",
        "test = llm_generate(\"Return JSON: {\\\"ok\\\": true}\")\n",
        "print(test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "router_system = \"\"\"\n",
        "you are a clinical assistant. Your task is to do lab and history extraction.\n",
        "Extract values exactly as written in text.\n",
        "If value is not explicitly written in text, return null. Do NOT guess.\n",
        "Do NOT modify numbers.\n",
        "Do NOT correct abnormal or impossible values.\n",
        "Copy numbers EXACTLY as written. Even if medically impossible.\n",
        "Extract these extract values from patient findings:\n",
        "- mcv(mean corpuscular volume): look for mcv or MCV with numbers behind it, output it in float\n",
        "- reticulocyte_count: look for \"Reticulocyte Count\", 'reticulocyte count'. 'retic' followed by a number.\n",
        "- megaloblastic: 1 if mentioned \"megaloblastic\" cells present in the finding of microscopic. 2 if there is a micropscipic infomation but not shown \"megaloblastic\" cell. 0 if there's no microscopic infomation.\n",
        "- CD_history:  1 if mentioned past chonic disease is present in the finding. 2 if finding tell patient \"Do not have chronic disease\" . 0 if there's no infomation about past chronic disease.\n",
        "- lead_histroy: 1 if mentioned \"working in factory\" is present in the finding. 2 if finding tell patient \"Do not have experiecne near factory\" . 0 if there's no infomation about patient having close contact in factory.\n",
        "Return only in JSON matching this exact structure. No explanation. \"\"\"\n",
        "Router_scheme = \"\"\" REQUIRED OUTPUT FORMAT( copy this structure exactly):\n",
        "{\n",
        "  \"mcv\": <number or null>,\n",
        "  \"reticulocyte_count\": <number or null>,\n",
        "  \"megaloblastic\": <number or null>,\n",
        "  \"CD_history\": <number or null>,\n",
        "  \"lead_histroy\": <number or null>,\n",
        "}\n",
        "Example:\n",
        "EXAMPLES (study these carefully):\n",
        "\n",
        "Input: \"patient retic 2, mcv 500, no history of chronic disease\"\n",
        "Think: I see \"retic 2\" so reticulocyte_count = 2 (exact copy)\n",
        "Think: I see \"mcv 500\" so mcv = 500 (exact copy, even though medically impossible)\n",
        "Think: I see \"no history of chronic disease\" so CD_history = 2\n",
        "Think: No microscopic info mentioned so megaloblastic = 0\n",
        "Think: No factory info mentioned so lead_history = 0\n",
        "Output: {\"mcv\": 500, \"reticulocyte_count\": 2, \"megaloblastic\": 0, \"CD_history\": 2, \"lead_history\": 0}\n",
        "\n",
        "Input: \"MCV 78.5, reticulocyte count 3.2, microscopy shows megaloblastic cells\"\n",
        "Think: I see \"MCV 78.5\" so mcv = 78.5 (exact copy including decimal)\n",
        "Think: I see \"reticulocyte count 3.2\" so reticulocyte_count = 3.2 (exact copy)\n",
        "Think: I see \"megaloblastic cells\" so megaloblastic = 1\n",
        "Think: No chronic disease info so CD_history = 0\n",
        "Think: No factory info so lead_history = 0\n",
        "Output: {\"mcv\": 78.5, \"reticulocyte_count\": 3.2, \"megaloblastic\": 1, \"CD_history\": 0, \"lead_history\": 0}\n",
        "\n",
        "Input: \"patient works in factory, mcv 1000, retic 15\"\n",
        "Think: I see \"mcv 1000\" so mcv = 1000 (exact copy, even though impossible)\n",
        "Think: I see \"retic 15\" so reticulocyte_count = 15 (exact copy)\n",
        "Think: I see \"works in factory\" so lead_history = 1\n",
        "Think: No microscopic info so megaloblastic = 0\n",
        "Think: No chronic disease info so CD_history = 0\n",
        "Output: {\"mcv\": 1000, \"reticulocyte_count\": 15, \"megaloblastic\": 0, \"CD_history\": 0, \"lead_history\": 1}\n",
        "\n",
        "Input: \"hemoglobin 8.2, platelets normal\"\n",
        "Think: I don't see mcv mentioned so mcv = null\n",
        "Think: I don't see reticulocyte mentioned so reticulocyte_count = null\n",
        "Think: No microscopic info so megaloblastic = 0\n",
        "Think: No chronic disease info so CD_history = 0\n",
        "Think: No factory info so lead_history = 0\n",
        "Output: {\"mcv\": null, \"reticulocyte_count\": null, \"megaloblastic\": 0, \"CD_history\": 0, \"lead_history\": 0}\n",
        "\n",
        "Now extract from this input. Show your thinking step by step, then output JSON.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VKShyo55ya3V"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def anemia_router(finding: str) -> str:\n",
        "  prompt = f\"\"\"\n",
        "  {router_system}\n",
        "  {Router_scheme}\n",
        "  Input: {finding}\n",
        "  Output:\n",
        "  \"\"\".strip()\n",
        "  response = llm_generate(prompt)\n",
        "  response = response.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "  start = response.rfind(\"{\")\n",
        "  end = response.rfind(\"}\")\n",
        "  if start != -1 and end != -1 and end > start:\n",
        "    response = response[start:end+1]\n",
        "  try:\n",
        "    return json.loads(response)\n",
        "  except Exception:\n",
        "    return {\n",
        "        \"error\": \"invalid_json\",\n",
        "        \"raw_output\": response\n",
        "    }"
      ],
      "metadata": {
        "id": "g2BOPRH5zZfB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = \"patient retic 2, mcv 500, no history of chronic disease\"\n",
        "anemia_router(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl-MsqoR1yyl",
        "outputId": "1bd6b325-083d-4af0-8125-5f18179873fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mcv': 500,\n",
              " 'reticulocyte_count': 2,\n",
              " 'megaloblastic': 0,\n",
              " 'CD_history': 2,\n",
              " 'lead_histroy': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    \"patient retic 2, mcv 500, no history of chronic disease\",\n",
        "    \"MCV 78.5, reticulocyte count 3.2, microscopy shows megaloblastic cells\",\n",
        "    \"patient works in factory, mcv 1000, retic 15\",\n",
        "    \"mcv 92.3, patient has diabetes\",\n",
        "]\n",
        "\n",
        "for i, test in enumerate(test_cases, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Test {i}: {test}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    result = anemia_router(test)\n",
        "    print(f\"Result: {json.dumps(result, indent=2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YSehk2J2CW5",
        "outputId": "52903db8-e295-4e2a-a412-41f4c681b06d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Test 1: patient retic 2, mcv 500, no history of chronic disease\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: {\n",
            "  \"mcv\": 500,\n",
            "  \"reticulocyte_count\": 2,\n",
            "  \"megaloblastic\": 0,\n",
            "  \"CD_history\": 2,\n",
            "  \"lead_histroy\": 0\n",
            "}\n",
            "\n",
            "============================================================\n",
            "Test 2: MCV 78.5, reticulocyte count 3.2, microscopy shows megaloblastic cells\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: {\n",
            "  \"mcv\": 78.5,\n",
            "  \"reticulocyte_count\": 3.2,\n",
            "  \"megaloblastic\": 1,\n",
            "  \"CD_history\": 0,\n",
            "  \"lead_histroy\": 0\n",
            "}\n",
            "\n",
            "============================================================\n",
            "Test 3: patient works in factory, mcv 1000, retic 15\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: {\n",
            "  \"mcv\": 1000,\n",
            "  \"reticulocyte_count\": 15,\n",
            "  \"megaloblastic\": 0,\n",
            "  \"CD_history\": 0,\n",
            "  \"lead_histroy\": 1\n",
            "}\n",
            "\n",
            "============================================================\n",
            "Test 4: mcv 92.3, patient has diabetes\n",
            "============================================================\n",
            "Result: {\n",
            "  \"error\": \"invalid_json\",\n",
            "  \"raw_output\": \"{\\\"mcv\\\": 92.3, \\\"reticulocyte_count\\\": null, \\\"megaloblastic\\\": 0, \\\"CD_history\\\": 0, \\\"lead_history\\\": 0} Step 1: Identify the key-value pairs we need to extract.\\nStep 2: Look for \\\"mcv\\\" which should be the mean corpuscular volume.\\nStep 3: Look for \\\"reticulocyte_count\\\".\\nStep 4: Look for any mention of \\\"megaloblastic\\\" cells.\\nStep 5: Look for any mention of \\\"chronic disease\\\".\\nStep 6: Look for any mention of \\\"factory exposure\\\".\\n\\nAnalysis:\\n\\n- The first line mentions \\\"mcv 92.3\\\". This indicates that the mean corpuscular volume (mcv) is 92.3.\\n- There is no mention of \\\"reticulocyte_count\\\" in the given information.\\n- There is no mention of \\\"megaloblastic\\\" cells in the given information.\\n- There is no mention of \\\"chronic disease\\\" in the given information.\\n- There is no mention of \\\"factory exposure\\\" in the given information.\\n\\nConclusion:\\n\\nThe extracted values are:\\n\\n{\\n  \\\"mcv\\\": 92.3,\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def anemia_logic_tool(data: dict) -> dict:\n",
        "    mcv = data.get(\"mcv\", None)\n",
        "    retic = data.get(\"reticulocyte_count\", None)\n",
        "    meg = data.get(\"megaloblastic\", None)  # 0/1/2\n",
        "    def missing(*vals):\n",
        "        return any(v is None for v in vals)\n",
        "    if mcv is None:\n",
        "        return {\"label\": \"need_more_data\", \"reason\": \"missing mcv\"}\n",
        "    if mcv < 80:\n",
        "        if retic is None:\n",
        "            return {\"label\": \"microcytic_need_retic\", \"reason\": \"mcv < 80 but missing reticulocyte_count\"}\n",
        "        if retic > 2.5:\n",
        "            return {\"label\": \"thalassemia\", \"reason\": \"mcv < 80 and retic > 2.5\"}\n",
        "        elif retic == 2.5:\n",
        "            return {\"label\": \"sideroblastic_or_anemia_of_chronic_disease\", \"reason\": \"mcv < 80 and retic == 2.5\"}\n",
        "        else:\n",
        "            return {\"label\": \"iron_deficiency\", \"reason\": \"mcv < 80 and retic < 2.5\"}\n",
        "    if 80 <= mcv <= 100:\n",
        "        if retic is None:\n",
        "            return {\"label\": \"normocytic_need_retic\", \"reason\": \"80<=mcv<=100 but missing reticulocyte_count\"}\n",
        "        if retic > 2.5:\n",
        "            return {\"label\": \"hemolysis_or_acute_blood_loss\", \"reason\": \"normocytic and retic > 2.5\"}\n",
        "        elif retic == 2.5:\n",
        "            return {\"label\": \"mixed_or_borderline\", \"reason\": \"normocytic and retic == 2.5\"}\n",
        "        else:\n",
        "            return {\"label\": \"anemia_of_chronic_disease_or_renal_or_bone_marrow\", \"reason\": \"normocytic and retic < 2.5\"}\n",
        "    if mcv > 100:\n",
        "        if meg == 1:\n",
        "            return {\"label\": \"b12_or_folate_deficiency\", \"reason\": \"mcv > 100 and megaloblastic present\"}\n",
        "        if meg == 2:\n",
        "            return {\"label\": \"non_megaloblastic_macrocytic\", \"reason\": \"mcv > 100 and not megaloblastic\"}\n",
        "        return {\"label\": \"macrocytic_need_smear\", \"reason\": \"mcv > 100 but no microscopic info\"}\n",
        "    return {\"label\": \"unclassified\", \"reason\": \"no rule matched\"}\n"
      ],
      "metadata": {
        "id": "WJ-VdTEJ6a-8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(anemia_logic_tool({\"mcv\": 72, \"reticulocyte_count\": 1.5, \"megaloblastic\": 0}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUaJ5fjGBCDF",
        "outputId": "0e782c4a-a406-43ff-ff12-45d49d2e2d86"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'iron_deficiency', 'reason': 'mcv < 80 and retic < 2.5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patient_text = \"patient reticulocyte 2, mcv 75, no microscopic info\"\n",
        "\n",
        "final_result = anemia_logic_tool(anemia_router(patient_text))\n",
        "\n",
        "print(final_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQ_0th8BaoL",
        "outputId": "e6c5b4e2-18bb-4bf7-b4e3-8e0915bd7e39"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': 'iron_deficiency', 'reason': 'mcv < 80 and retic < 2.5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def run_anemia(text):\n",
        "    extracted = anemia_router(text)\n",
        "    result = anemia_logic_tool(extracted)\n",
        "    return result\n",
        "\n",
        "gr.Interface(\n",
        "    fn=run_anemia,\n",
        "    inputs=\"textbox\",\n",
        "    outputs=\"json\",\n",
        "    title=\"Anemia Helper\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "n1w23W64DbJm",
        "outputId": "d37e14bb-814f-460e-851a-cb263916bc70"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3c529c8ad7f417dfd4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3c529c8ad7f417dfd4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwe6VcSsGRU5",
        "outputId": "5304d1fb-cb91-4eef-e999-e2fbfc499172"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PQ05LCLuAxzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JITkd3-TGwB6"
      }
    }
  ]
}